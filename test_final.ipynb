{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55X-sl0Md626",
        "outputId": "bbaff959-60fc-4193-e2a0-40587cb4245f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, activations, models, preprocessing, utils\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import nltk\n",
        "import sqlite3\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/classification_v2.json', 'r') as j:\n",
        "     contents = json.loads(j.read())\n",
        "\n",
        "def preprocess_and_tokenize_sentences(text):\n",
        "    text = text.lower()\n",
        "    # text = re.sub(r'[^a-zA-Z\\s?.]', '', text)\n",
        "    text = text.replace('?','')\n",
        "    sentences = sent_tokenize(text)\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "cPVH6MrWeFfO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_data= pd.read_csv('/content/chatbot_dataset_4.csv')\n",
        "chatbot_data['cauhoi'] = chatbot_data['cauhoi'].astype(str)\n",
        "chatbot_data['traloi'] = chatbot_data['traloi'].astype(str)\n",
        "questions= chatbot_data['cauhoi'].tolist()"
      ],
      "metadata": {
        "id": "4Tfg9R1NeOli"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_list=[]\n",
        "sentences_list= []\n",
        "for intents in contents['Intenst']:\n",
        "    tags= intents['Tags']\n",
        "    questions = intents['Questions']\n",
        "    for question in questions:\n",
        "        tags_list.append(tags)\n",
        "        sentences = preprocess_and_tokenize_sentences(question)\n",
        "        # print(sentences)\n",
        "        sentences_list.extend(sentences)"
      ],
      "metadata": {
        "id": "LFiJVDS5eTPa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_data = pd.DataFrame({'Sentence': sentences_list,'Tag': tags_list})\n",
        "classification_data = classification_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "classification_data.to_csv('classification.csv',index=False)"
      ],
      "metadata": {
        "id": "t3gwCE_YeWYU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_data = pd.read_csv('/content/classification.csv')\n",
        "classification_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qUMhzWboeYHz",
        "outputId": "232cf92a-49a9-4ab0-ea32-b85a1f5a85db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence                    Tag\n",
              "0  what financial outlay is expected for the acqu...       Information tags\n",
              "1  what would be the purchase cost including taxe...       Information tags\n",
              "2  what would the xiaomi redmi note 11 4gb-128gb ...       Information tags\n",
              "3  am i able to reserve items that aren't in stoc...  Non-Informations tags\n",
              "4  could i see a demonstration of the product bef...  Non-Informations tags"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1813b8ab-4abb-4774-bf60-cf917f55c866\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what financial outlay is expected for the acqu...</td>\n",
              "      <td>Information tags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what would be the purchase cost including taxe...</td>\n",
              "      <td>Information tags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what would the xiaomi redmi note 11 4gb-128gb ...</td>\n",
              "      <td>Information tags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>am i able to reserve items that aren't in stoc...</td>\n",
              "      <td>Non-Informations tags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>could i see a demonstration of the product bef...</td>\n",
              "      <td>Non-Informations tags</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1813b8ab-4abb-4774-bf60-cf917f55c866')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1813b8ab-4abb-4774-bf60-cf917f55c866 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1813b8ab-4abb-4774-bf60-cf917f55c866');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9028237-927f-49b5-bcc0-0cb752e85679\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9028237-927f-49b5-bcc0-0cb752e85679')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9028237-927f-49b5-bcc0-0cb752e85679 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_mapping = {\n",
        "    'Information tags': 1,\n",
        "    'Non-Informations tags': 0\n",
        "}\n",
        "classification_data['Tag'] = classification_data['Tag'].map(labels_mapping)"
      ],
      "metadata": {
        "id": "mcfDsnVTefWI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = classification_data.Sentence\n",
        "Y = classification_data.Tag\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "classification_data.sample(10)\n",
        "\n",
        "all_texts = classification_data['Sentence'].tolist() + chatbot_data['cauhoi'].tolist() + chatbot_data['traloi'].tolist()"
      ],
      "metadata": {
        "id": "VxJ-GTTAeiMZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 18\n",
        "tokenizer = Tokenizer(oov_token='OOV')\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "# print(X_train_sequences)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "TUyu1njselYk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(vocab_size,30,input_length=max_len)(inputs)\n",
        "    layer = LSTM(16)(layer)\n",
        "    layer = Dense(8,name='FC1')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model\n",
        "\n",
        "model_1 = model()\n",
        "model_1.summary()\n",
        "model_1.compile(loss=\"binary_crossentropy\", optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJdi6vpVem6b",
        "outputId": "a12a1111-0c25-4855-b05a-1555af9039fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 18)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 18, 30)            86160     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16)                3008      \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8)                 0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89313 (348.88 KB)\n",
            "Trainable params: 89313 (348.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model_1.fit(X_train_padded, Y_train, validation_data=(X_test_padded, Y_test) ,epochs=10,batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nfachOZepqL",
        "outputId": "9a8fcb01-228f-4d4a-93be-a0ab46bb5e36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 17s 98ms/step - loss: 0.6341 - accuracy: 0.6722 - val_loss: 0.3564 - val_accuracy: 0.9524\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1312 - accuracy: 0.9722 - val_loss: 0.1858 - val_accuracy: 0.9524\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9944 - val_loss: 4.9691e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.3360e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.4181e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9889 - val_loss: 1.0409e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.7215e-06 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = chatbot_data['cauhoi'].tolist()\n",
        "answers = chatbot_data[\"traloi\"].to_list()\n",
        "answers_with_tags = list()\n",
        "#lấy ra từ điển\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        questions.pop( i )\n",
        "answers = list()\n",
        "\n",
        "#gan nhan\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "# tokenizer = preprocessing.text.Tokenizer()\n",
        "# tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index ) + 1\n",
        "# print( 'Số lượng từ trong từ điển: {}'.format( VOCAB_SIZE ))\n",
        "\n",
        "#trích thành các từ xl các kí tự đặc biệt\n",
        "vocab = []\n",
        "for word in tokenizer.word_index:\n",
        "  vocab.append(word)"
      ],
      "metadata": {
        "id": "R7FO3b1leqS0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "# print(  )\n",
        "# print(\"Decoder_input_data\",decoder_input_data.shape , maxlen_answers)\n",
        "# print(answers[0])\n",
        "# print(decoder_input_data[0])\n",
        "\n",
        "# decoder_output_data giải mã từ vector số sang string\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "# print(  )\n",
        "# print(\"Decoder_output_data\", decoder_output_data.shape)\n",
        "# print(answers[0])\n",
        "# print(decoder_output_data[0])\n",
        "\n",
        "#khởi tạo mô hình lstm\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "print(encoder_outputs)\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax )\n",
        "output = decoder_dense ( decoder_outputs )\n",
        "print(output)\n",
        "\n",
        "model_2= tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model_2.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW7vLm67jKGf",
        "outputId": "b1747442-acf5-4e7b-d338-d26108126f60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 200), dtype=tf.float32, name=None), name='lstm_1/PartitionedCall:0', description=\"created by layer 'lstm_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 110, 2872), dtype=tf.float32, name=None), name='dense/Softmax:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 40)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 110)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 40, 200)              574400    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 110, 200)             574400    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 200),                320800    ['embedding_1[0][0]']         \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 110, 200),           320800    ['embedding_2[0][0]',         \n",
            "                              (None, 200),                           'lstm_1[0][1]',              \n",
            "                              (None, 200)]                           'lstm_1[0][2]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 110, 2872)            577272    ['lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2367672 (9.03 MB)\n",
            "Trainable params: 2367672 (9.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size= 1, epochs=3 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQsWsablfyaK",
        "outputId": "52fb6c2e-63fb-4ea7-ad64-124f319661fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "857/857 [==============================] - 28s 19ms/step - loss: 6.1052\n",
            "Epoch 2/3\n",
            "857/857 [==============================] - 10s 12ms/step - loss: 5.7854\n",
            "Epoch 3/3\n",
            "857/857 [==============================] - 10s 11ms/step - loss: 5.6347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7af8208d0580>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference_models():\n",
        "\n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    print(encoder_model)\n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "\n",
        "    decoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    return encoder_model , decoder_model\n",
        "\n",
        "def str_to_tokens( sentence : str ):\n",
        "\n",
        "    words = sentence.lower().replace(\"?\",\"\").split()\n",
        "    tokens_list = list()\n",
        "\n",
        "    for word in words:\n",
        "        try:\n",
        "            tokens_list.append( tokenizer.word_index[ word ] )\n",
        "        except:\n",
        "            tokens_list.append(tokenizer.word_index['i dont know'])\n",
        "\n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n",
        "\n",
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "def chat_bot_lstm(cau_hoi):\n",
        "    states_values = enc_model.predict( str_to_tokens( cau_hoi ) )\n",
        "#     print(states_values)\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ]\n",
        "    return ( decoded_translation[1:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pYgq6gRjmZI",
        "outputId": "4e21fa76-1967-482a-a030-d966bb097840"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.engine.functional.Functional object at 0x7af7b07d7e50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_bot_lstm('hello'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKjYUWNJjpmI",
        "outputId": "1f873263-d702-4c02-8eb5-b7c468d46afb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(user_input_padded,thershold=0.002):\n",
        "    predict = model_1.predict(user_input_padded)\n",
        "    print(user_input_padded)\n",
        "    print(predict)\n",
        "    if predict[0] >= thershold:\n",
        "        return 'Information Tag'\n",
        "    else:\n",
        "        return 'Non-Information Tag'"
      ],
      "metadata": {
        "id": "w1d-KDrxjsQ5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_padding(input_padded):\n",
        "    unpadded_input = []\n",
        "    for sequence in input_padded:\n",
        "        sentence = [word for word in sequence if word != 0]  # Assuming 0 is the padding token\n",
        "        # print(sentence)\n",
        "        unpadded_input.append(sentence)\n",
        "    return unpadded_input\n",
        "\n",
        "# Reverse the tokenization\n",
        "def reverse_tokenization(sequences, tokenizer):\n",
        "    original_sentences = []\n",
        "    for sequence in sequences:\n",
        "        # print(sequence)\n",
        "        original_sentence = tokenizer.sequences_to_texts([sequence])[0]\n",
        "        # print(original_sentence)\n",
        "        original_sentences.append(original_sentence)\n",
        "    return original_sentences"
      ],
      "metadata": {
        "id": "-WFI8Zcdl2L1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tokenize(text):\n",
        "  words = word_tokenize(text)\n",
        "  tags = pos_tag(words)\n",
        "  selected_words = [word for word, tag in tags if tag in ['NN', 'NNP','CD','JJ']]\n",
        "  return selected_words"
      ],
      "metadata": {
        "id": "Mz40bl3ul5S1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_tags(predict):\n",
        "  if predict == 'Information Tag':\n",
        "      original_user_input = temp\n",
        "      price_tags = [\n",
        "    'cost', 'price', 'how much', 'sell', 'budget', 'quotation', 'amount',\"lowest price\",\"total\"\n",
        "    'market value', 'pricing information', 'price list', 'price range',\"final cost\",\"sale price\"\n",
        "    'purchase cost', 'price point', 'expense', 'valuation',\"rate\", \"cost range\",\"price estimation\"\n",
        "    'invoice','list price', 'top price', 'bottom price',\"retail price\",\"expenditure\"\n",
        "    'final price', 'bill',\"sold\",\"purchase\",\"spend\",\"pay\",\"price tag\",\"current price\",'much'\n",
        "]\n",
        "      screen_resolution_tags = [\n",
        "    'screen resolution', 'clarity', 'Full HD', 'Retina display', 'contrast level',\n",
        "    'color reproduction', 'OLED display', 'LCD display', 'brightness setting',\n",
        "    'glare-resistant screen', 'refresh rate', '4K resolution',\n",
        "    'QHD display', 'IPS technology', 'AMOLED screen', 'pixel density',\n",
        "    'display quality', 'picture quality', 'PPI', 'HD', 'visual sharpness',\n",
        "    'display specs', 'image definition', 'aspect ratio', 'contrast ratio',\n",
        "    'color accuracy', 'brightness levels', 'display type', 'screen clarity',\n",
        "    'viewing experience', 'pixels','screen','size','screen size','resolution'\n",
        "]\n",
        "      phone_memory_keywords = [\n",
        "    \"memory\", \"storage\", \"GB\", \"TB\", \"storage space\", \"capacity\", \"ram\",\n",
        "    \"internal memory\", \"Built-in Storage\", \"Phone Storage\", \"External Storage\",\n",
        "    \"expandable storage\", \"Memory Card Slot\", \"microSD Support\", \"microSD Slot\",\n",
        "    \"UFS\", \"Memory Upgrade\", \"Storage Expansion\", \"rom\", \"system memory\",\n",
        "    \"user available memory\", \"cache memory\", \"phone memory\", \"device storage\",\n",
        "    \"onboard storage\", \"Secure Storage\", \"Memory Card Capacity\",\n",
        "    \"Dual SIM with Memory Card Slot\", \"LPDDR4\", \"LPDDR5\",\n",
        "    \"Read-Only Memory\", \"Flash Memory\", \"eMMC\", \"NVMe\",\n",
        "    \"USB OTG Support\", \"Memory Efficiency\", \"High-Speed Memory\",\n",
        "    \"Memory Bandwidth\", \"Storage Speed\", \"Memory Card Compatibility\"\n",
        "]\n",
        "\n",
        "      # information_tags = ['information']\n",
        "      tokenize = pos_tokenize(original_user_input)\n",
        "      # print(tokenize)\n",
        "      for keyword in tokenize:\n",
        "        if keyword in price_tags:\n",
        "          filtered_elements = [element for element in tokenize if element not in price_tags]\n",
        "          concatenated_string = ' '.join(filtered_elements)\n",
        "          return 'price_tag', concatenated_string\n",
        "        elif keyword in screen_resolution_tags:\n",
        "          filtered_elements = [element for element in tokenize if element not in screen_resolution_tags]\n",
        "          concatenated_string = ' '.join(filtered_elements)\n",
        "          return 'resolution_tag', concatenated_string\n",
        "        elif keyword in phone_memory_keywords:\n",
        "          filtered_elements = [element for element in tokenize if element not in screen_resolution_tags]\n",
        "          concatenated_string = ' '.join(filtered_elements)\n",
        "          return 'memory_tag', concatenated_string\n",
        "  else:\n",
        "    original_user_input = temp\n",
        "    return \"Non-Information Tag\",chat_bot_lstm(original_user_input)\n"
      ],
      "metadata": {
        "id": "MAcrx7Esl7UN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter your question: \")\n",
        "temp = user_input\n",
        "# original_user_input = user_input\n",
        "# Preprocess and tokenize user input\n",
        "user_input = preprocess_and_tokenize_sentences(user_input)\n",
        "user_input_sequences = tokenizer.texts_to_sequences(user_input)\n",
        "user_input_padded = pad_sequences(user_input_sequences, maxlen=max_len, padding='post')\n",
        "user_input_padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQVWDcN-mRNy",
        "outputId": "ef88f05e-65d7-43e9-fcbe-4b06bc4803f5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question: what is the storage of Iphone 15?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 15,   9,   2, 372,  13,  45,  98,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = prediction(user_input_padded)\n",
        "predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "z-clc3X-mU1m",
        "outputId": "7c8e4e89-3e16-4c4d-a1b1-876918ed9709"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[ 15   9   2 372  13  45  98   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "[[2.8725024e-05]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Non-Information Tag'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_tags(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIZvHUwPmWTG",
        "outputId": "accd7a4d-a86c-495a-f52b-db1219a1d076"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Non-Information Tag',\n",
              " 'yes we can a payment of the payment of the payment of the payment')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S1v9Bs0tm8Ga"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}